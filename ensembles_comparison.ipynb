{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AMPpred_MFA.lib.Data import *\n",
    "from AMPpred_MFA.lib.Visualization import colorful_print, current_time, draw_roc\n",
    "from AMPpred_MFA.lib.Encoding import AAC\n",
    "from AMPpred_MFA.lib.Visualization import *\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    StackingClassifier,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams.update({\"font.size\": 26})  # 设置全局字体大小\n",
    "CPU_NUM_CORES = joblib.cpu_count(only_physical_cores=True)\n",
    "print(f\"Number of physical cores: {CPU_NUM_CORES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = \"Decision Tree\"\n",
    "RF = \"Random Forest\"\n",
    "ADABOOST = \"AdaBoost\"\n",
    "XGBOOST = \"XGBoost\"\n",
    "STACKING = \"Stacking\"\n",
    "\n",
    "params = {\n",
    "    DT: {\n",
    "        \"criterion\": \"gini\",\n",
    "        \"max_depth\": 6,\n",
    "        \"max_features\": None,\n",
    "        \"min_samples_leaf\": 4,\n",
    "        \"min_samples_split\": 10,\n",
    "    },\n",
    "    RF: {\n",
    "        \"criterion\": \"entropy\",\n",
    "        \"max_depth\": None,\n",
    "        \"max_features\": \"sqrt\",\n",
    "        \"min_samples_leaf\": 1,\n",
    "        \"min_samples_split\": 2,\n",
    "        \"n_estimators\": 300,\n",
    "    },\n",
    "    ADABOOST: {\"algorithm\": \"SAMME.R\", \"learning_rate\": 0.1, \"n_estimators\": 300},\n",
    "    XGBOOST: {\n",
    "        \"colsample_bytree\": 0.6,\n",
    "        \"gamma\": 0,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"max_depth\": 10,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"n_estimators\": 300,\n",
    "        \"subsample\": 1,\n",
    "    },\n",
    "}\n",
    "\n",
    "models = {\n",
    "    DT: DecisionTreeClassifier(),\n",
    "    RF: RandomForestClassifier(),\n",
    "    ADABOOST: AdaBoostClassifier(),\n",
    "    XGBOOST: XGBClassifier(),\n",
    "    STACKING: StackingClassifier(\n",
    "        estimators=[\n",
    "            (RF, RandomForestClassifier(**params[RF])),\n",
    "            (ADABOOST, AdaBoostClassifier(**params[ADABOOST])),\n",
    "            (XGBOOST, XGBClassifier(**params[XGBOOST])),\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(),\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练并返回模型\n",
    "def ensembles_training(models: dict, file_path_train, feature_function):\n",
    "    X_train, y_train = build_dataset_from_format(file_path_train, feature_function)\n",
    "    for name in models:\n",
    "        print(\"{} is training...\".format(name))\n",
    "        models[name].fit(X_train, y_train)\n",
    "    return models\n",
    "\n",
    "\n",
    "\n",
    "# 测试模型并返回评估指标\n",
    "def ensembles_testing(models: dict, file_path_test, feature_function, roc_flag=False):\n",
    "    test_metrics = {}\n",
    "    test_roc = {}\n",
    "    X_test, y_test = build_dataset_from_format(file_path_test, feature_function)\n",
    "    for name in models:\n",
    "        print(\"{} is testing...\".format(name))\n",
    "        cr = {}\n",
    "        model = models[name]\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "        auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "        TN, FP, FN, TP = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
    "        cr[\"AUC\"] = auc\n",
    "        cr[\"Acc\"] = (TN + TP) / (TN + FP + FN + TP)\n",
    "        cr[\"MCC\"] = ((TP * TN) - (FP * FN)) / (\n",
    "            np.sqrt((TP + FN) * (TP + FP) * (TN + FP) * (TN + FN))\n",
    "        )\n",
    "        cr[\"Sn\"] = TP / (TP + FN)\n",
    "        cr[\"Sp\"] = TN / (TN + FP)\n",
    "        cr[\"CM\"] = str(cm.tolist())\n",
    "        test_metrics[name] = cr\n",
    "\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "        test_roc[name] = (auc, fpr, tpr)\n",
    "    if roc_flag:\n",
    "        return test_metrics, test_roc\n",
    "    return test_metrics\n",
    "\n",
    "\n",
    "\n",
    "# 将模型训练并测试一次，返回测试集上的性能评估指标\n",
    "def ensembles_training_testing(\n",
    "    models: dict, file_path_train, file_path_test, feature_function\n",
    "):\n",
    "    models = ensembles_training(models, file_path_train, feature_function)\n",
    "    test_metrics = ensembles_testing(models, file_path_test, feature_function)\n",
    "\n",
    "\n",
    "    return test_metrics\n",
    "\n",
    "\n",
    "# 绘制不同数据集上的roc，key为方法名，value为3元组:(auc,[tpr],[fpr])\n",
    "def draw_rocs(rocs, title=\"ROC curve\"):\n",
    "    colors = plt.get_cmap(\"tab20\").colors\n",
    "    colors_dict = {\n",
    "        method: colors[i % len(colors)] for i, method in enumerate(rocs.keys())\n",
    "    }\n",
    "    roc_fig = plt.figure(figsize=(12, 12))\n",
    "    fig = plt.subplot(1, 1, 1)\n",
    "    fig.set_xlim([0.0, 1.0])\n",
    "    fig.set_ylim([0.0, 1.0])\n",
    "    fig.set_title(title, fontsize=36)\n",
    "    fig.set_xlabel(\"False Positive Rate\")\n",
    "    fig.set_ylabel(\"True Positive Rate\")\n",
    "    fig.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Random\", alpha=0.8)\n",
    "\n",
    "    roc_auc = [(method, rocs[method][0]) for method in rocs.keys()]\n",
    "    roc_auc.sort(key=lambda x: x[1])\n",
    "    roc_auc = dict(roc_auc)\n",
    "\n",
    "    for method in roc_auc:\n",
    "        fpr, tpr = rocs[method][1], rocs[method][2]\n",
    "        fig.plot(\n",
    "            fpr,\n",
    "            tpr,\n",
    "            lw=2,\n",
    "            color=colors_dict[method],\n",
    "            label=\"{} (AUC = {:.3f})\".format(method, roc_auc[method]),\n",
    "        )\n",
    "\n",
    "    fig.legend(loc=\"lower right\")\n",
    "    return roc_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5次独立重复实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPEAT_TIMES = 5\n",
    "path_train_base = \"./dataset/train/{}_trial/train.fasta\"\n",
    "path_test_base = \"./dataset/test/our_testset/{}_trial/test.fasta\"\n",
    "path_saving_base = \"./result/ensembles_in_{}_trials\".format(REPEAT_TIMES)\n",
    "os.makedirs(path_saving_base, exist_ok=True)\n",
    "\n",
    "metrics_total = {name: [] for name in models}\n",
    "for i in range(REPEAT_TIMES):\n",
    "    print(\"{}\\nThe {} times training and testing...\".format(\"=\" * 50, i + 1))\n",
    "    file_path_train = path_train_base.format(i + 1)\n",
    "    file_path_test = path_test_base.format(i + 1)\n",
    "    metrics_current = ensembles_training_testing(\n",
    "        models, file_path_train, file_path_test, AAC\n",
    "    )\n",
    "    for name in metrics_current:\n",
    "        metrics_total[name].append(metrics_current[name])\n",
    "\n",
    "for name in models:\n",
    "    save_path = os.path.join(path_saving_base, name + \".csv\")\n",
    "    df_metrics = pd.DataFrame(metrics_total[name])\n",
    "    df_mean = []\n",
    "    for col in df_metrics:\n",
    "        if col == \"CM\":\n",
    "            df_mean.append(\n",
    "                np.array([eval(i) for i in df_metrics[col].tolist()])\n",
    "                .mean(axis=0)\n",
    "                .astype(int)\n",
    "                .tolist()\n",
    "            )\n",
    "        else:\n",
    "            df_mean.append(\n",
    "                str(round(df_metrics[col].mean(), 3))\n",
    "                + \"±\"\n",
    "                + str(round(df_metrics[col].std(), 3))\n",
    "            )\n",
    "    df_metrics.insert(\n",
    "        0,\n",
    "        \"Trial Number\",\n",
    "        [\"{} th\".format(i + 1) for i in range(len(df_metrics))],\n",
    "        allow_duplicates=False,\n",
    "    )\n",
    "    df_metrics.loc[len(df_metrics)] = [\"Mean\"] + df_mean\n",
    "    df_metrics.to_csv(save_path, index=False, encoding=\"ansi\")\n",
    "    print(\n",
    "        \"{}'s training and testing result has been saved in: {}\".format(name, save_path)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_TIMES = 10\n",
    "path_train_base = \"./dataset/10_fold_validation/{}_fold/train.fasta\"\n",
    "path_test_base = \"./dataset/10_fold_validation/{}_fold/test.fasta\"\n",
    "path_saving_base = \"./result/ensembles_in_{}_fold_cross_validation\".format(\n",
    "    FOLD_TIMES)\n",
    "os.makedirs(path_saving_base, exist_ok=True)\n",
    "\n",
    "metrics_total = {name: [] for name in models}\n",
    "for i in range(FOLD_TIMES):\n",
    "    print(\n",
    "        \"{}\\nThe {}-fold cross validation training and testing...\".format(\n",
    "            \"=\" * 50, i + 1\n",
    "        )\n",
    "    )\n",
    "    file_path_train = path_train_base.format(i + 1)\n",
    "    file_path_test = path_test_base.format(i + 1)\n",
    "    metrics_current = ensembles_training_testing(\n",
    "        models, file_path_train, file_path_test, AAC\n",
    "    )\n",
    "    for name in metrics_current:\n",
    "        metrics_total[name].append(metrics_current[name])\n",
    "\n",
    "for name in models:\n",
    "    save_path = os.path.join(path_saving_base, name + \".csv\")\n",
    "    df_metrics = pd.DataFrame(metrics_total[name])\n",
    "    df_mean = []\n",
    "    for col in df_metrics:\n",
    "        if col == \"CM\":\n",
    "            df_mean.append(\n",
    "                np.array([eval(i) for i in df_metrics[col].tolist()])\n",
    "                .mean(axis=0)\n",
    "                .astype(int)\n",
    "                .tolist()\n",
    "            )\n",
    "        else:\n",
    "            df_mean.append(\n",
    "                str(round(df_metrics[col].mean(), 3))\n",
    "                + \"±\"\n",
    "                + str(round(df_metrics[col].std(), 3))\n",
    "            )\n",
    "    df_metrics.insert(\n",
    "        0,\n",
    "        \"Fold Number\",\n",
    "        [\"{}\".format(i + 1) for i in range(len(df_metrics))],\n",
    "        allow_duplicates=False,\n",
    "    )\n",
    "    df_metrics.loc[len(df_metrics)] = [\"Mean\"] + df_mean\n",
    "    df_metrics.to_csv(save_path, index=False, encoding=\"ansi\")\n",
    "    print(\n",
    "        \"{}'s training and testing result has been saved in: {}\".format(\n",
    "            name, save_path)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在Xu等人的数据集上的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"./dataset/train/1_trial/train.fasta\"\n",
    "path_test_base = \"./dataset/test/other_testset/\"\n",
    "path_saving_base = \"./result/ensembles_in_Xu_testset\"\n",
    "path_saving_roc = os.path.join(path_saving_base, \"roc.png\")\n",
    "\n",
    "# 在原始数据集上训练模型\n",
    "models = ensembles_training(models, path_train, AAC)\n",
    "\n",
    "# 在xu等人的数据集上测试模型\n",
    "testset_names = []\n",
    "metrics_total = {name: [] for name in models}\n",
    "roc_total = {}\n",
    "for testset_name in os.listdir(path_test_base):\n",
    "    print(\"\\n{}{}{}\".format(\"=\" * 20, testset_name, \"=\" * 20))\n",
    "    file_path_test = os.path.join(path_test_base, testset_name, \"test.fasta\")\n",
    "    metrics_current, roc_current = ensembles_testing(\n",
    "        models, file_path_test, AAC, roc_flag=True\n",
    "    )\n",
    "    for name in metrics_current:\n",
    "        metrics_total[name].append(metrics_current[name])\n",
    "    roc_total[testset_name] = roc_current\n",
    "    testset_names.append(testset_name)\n",
    "\n",
    "# 保存模型的性能评估指标\n",
    "for name in models:\n",
    "    save_dir = os.path.join(path_saving_base, name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, name + \".csv\")\n",
    "    df_metrics = pd.DataFrame(metrics_total[name])\n",
    "    df_metrics.insert(\n",
    "        0,\n",
    "        \"Test set\",\n",
    "        testset_names,\n",
    "        allow_duplicates=False,\n",
    "    )\n",
    "\n",
    "    df_metrics.to_csv(save_path, index=False, encoding=\"ansi\")\n",
    "\n",
    "    print(\"{}'s testing result has been saved in: {}\".format(name, save_path))\n",
    "\n",
    "# 绘制ROC曲线\n",
    "fig_roc, ax = plt.subplots(2, 4, figsize=(20, 10))\n",
    "ax = ax.flatten()\n",
    "for i, testset_name in enumerate(roc_total):\n",
    "    fig_current = draw_rocs(roc_total[testset_name], testset_name)\n",
    "    fig_current.subplots_adjust(left=0.1, right=0.95, top=0.95, bottom=0.1)\n",
    "    fig_current.canvas.draw()\n",
    "    im_current = Image.frombytes(\n",
    "        \"RGB\", fig_current.canvas.get_width_height(), fig_current.canvas.tostring_rgb()\n",
    "    )\n",
    "    ax[i].imshow(im_current)\n",
    "    ax[i].set_axis_off()\n",
    "    plt.close(fig_current)\n",
    "fig_roc.tight_layout()\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "path_saving_roc = os.path.join(path_saving_base, \"roc.png\")\n",
    "fig_roc.savefig(path_saving_roc, dpi=300, bbox_inches=\"tight\")\n",
    "print(\"ROC figure has been saved in: {}\".format(path_saving_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
